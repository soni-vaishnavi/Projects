{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ff15456-b8a8-496f-a286-7e014c47533e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries for EDA\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    " \n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    " \n",
    "# Importing libraries necessary for Model Building and Training\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    " \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c550687-8411-4026-a171-e8abb41d83bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained model\n",
    "model = tf.keras.models.load_model('C:/Users/sachi/Spam Email Identification Project Using AI/Model.h5')\n",
    "x=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86078f8a-379d-441a-92fd-016c89d35cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer\n",
    "with open('C:/Users/sachi/Spam Email Identification Project Using AI/tokenizer.pkl', 'rb') as file:\n",
    "    tokenizer = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8568987-d29a-4a7a-aebe-5c789264a245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a text message (type 'exit' to end):  dsa\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step\n",
      "Prediction Probability: [0.9975581]\n",
      "The entered text is classified as: Spam\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a text message (type 'exit' to end):  @@\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n",
      "Prediction Probability: [0.9975551]\n",
      "The entered text is classified as: Spam\n"
     ]
    }
   ],
   "source": [
    "# Maximum sequence length used during tokenization and padding\n",
    "max_len = 100\n",
    "\n",
    "# Text preprocessing functions\n",
    "def remove_subject(text):\n",
    "    return text.replace('Subject', '')\n",
    "\n",
    "def remove_punctuations(text):\n",
    "    punctuations_list = string.punctuation\n",
    "    temp = str.maketrans('', '', punctuations_list)\n",
    "    return text.translate(temp)\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    stop_words = stopwords.words('english')\n",
    " \n",
    "    imp_words = []\n",
    " \n",
    "    # Storing the important words\n",
    "    for word in str(text).split():\n",
    "        word = word.lower()\n",
    " \n",
    "        if word not in stop_words:\n",
    "            imp_words.append(word)\n",
    " \n",
    "    output = \" \".join(imp_words)\n",
    " \n",
    "    return output\n",
    "\n",
    "threshold = 0.5  # Default threshold\n",
    "\n",
    "def set_threshold(new_threshold):\n",
    "    global threshold\n",
    "    threshold = new_threshold\n",
    "    print(f'Threshold set to: {threshold}')\n",
    "\n",
    "# Function to preprocess user input and make predictions\n",
    "def preprocess_text(user_input):\n",
    "    # Apply your preprocessing functions\n",
    "    user_input = remove_subject(user_input)\n",
    "    user_input = remove_punctuations(user_input)\n",
    "    user_input = remove_stopwords(user_input)\n",
    "\n",
    "    # Tokenize and pad the preprocessed input\n",
    "    sequences = tokenizer.texts_to_sequences([user_input])\n",
    "    padded_sequences = pad_sequences(sequences, maxlen=max_len, padding='post', truncating='post')\n",
    "\n",
    "    return padded_sequences\n",
    "\n",
    "def predict_spam_or_not_spam(user_input):\n",
    "    # Preprocess the user input\n",
    "    preprocessed_input = preprocess_text(user_input)\n",
    "\n",
    "    # Make predictions\n",
    "    prediction = model.predict(preprocessed_input)\n",
    "\n",
    "    # Print the prediction probability\n",
    "    print(f'Prediction Probability: {prediction[0]}')\n",
    "\n",
    "    # Interpret the prediction\n",
    "    if prediction[0] >= threshold:\n",
    "        return \"Spam\"\n",
    "    else:\n",
    "        return \"Not Spam\"\n",
    "\n",
    "# Get user input with input validation\n",
    "while True:\n",
    "    user_text = input(\"Enter a text message (type 'exit' to end): \")\n",
    "\n",
    "    # Check for exit condition\n",
    "    if user_text.lower() == 'exit':\n",
    "        print(\"Exiting the program.\")\n",
    "        break\n",
    "\n",
    "    try:\n",
    "        # Predict and display the result\n",
    "        result = predict_spam_or_not_spam(user_text)\n",
    "        print(f'The entered text is classified as: {result}')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        print(\"Please enter a valid text message.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd93f961-02e7-4608-971b-e04d9fe0a5f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7589ffcc-5422-4689-ba68-b8e52e3d339a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
